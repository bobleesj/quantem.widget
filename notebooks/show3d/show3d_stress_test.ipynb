{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    %env ANYWIDGET_HMR=1\n",
    "except Exception:\n",
    "    pass  # autoreload unavailable (Colab Python 3.12+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import quantem.widget\n",
    "from quantem.widget import Show3D\n",
    "print(f\"quantem.widget {quantem.widget.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic focal series (crystal lattice with evolving defocus)\n",
    "Through-focal series of a hexagonal crystal lattice using FFT-based convolution:\n",
    "- Sharp atomic columns at focus, heavily blurred away from focus\n",
    "- Fresnel-like concentric fringes that grow with defocus magnitude\n",
    "- Nanoparticle boundary ring for additional visual interest\n",
    "- Light Poisson noise (high dose so noise doesn't dominate the defocus effects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_focal_series(n_frames, size, device=\"cpu\"):\n",
    "    \"\"\"Generate through-focal series \u2014 key-frame interpolation, fully vectorized.\"\"\"\n",
    "    t0 = time.time()\n",
    "    # Frequency grids\n",
    "    fy = torch.fft.fftfreq(size, device=device).unsqueeze(1)\n",
    "    fx = torch.fft.fftfreq(size, device=device).unsqueeze(0)\n",
    "    freq_r2 = fy ** 2 + fx ** 2\n",
    "    # Build lattice via FFT: impulses at atom sites convolved with Gaussian\n",
    "    spacing = size / 10\n",
    "    atom_sigma = spacing * 0.06\n",
    "    impulses = torch.zeros(size, size, device=device)\n",
    "    for i in range(-2, 15):\n",
    "        for j in range(-2, 15):\n",
    "            cx = i * spacing + (j % 2) * spacing * 0.5\n",
    "            cy = j * spacing * 0.866\n",
    "            ix, iy = int(round(cx)), int(round(cy))\n",
    "            if 0 <= ix < size and 0 <= iy < size:\n",
    "                impulses[iy, ix] = 1.0\n",
    "    gauss_atom = torch.exp(-2 * np.pi ** 2 * atom_sigma ** 2 * freq_r2)\n",
    "    lattice_fft = torch.fft.fft2(impulses) * gauss_atom\n",
    "    # Nanoparticle boundary ring\n",
    "    y = torch.linspace(0, size - 1, size, device=device)\n",
    "    x = torch.linspace(0, size - 1, size, device=device)\n",
    "    yy, xx = torch.meshgrid(y, x, indexing=\"ij\")\n",
    "    r_center = torch.sqrt((xx - size / 2) ** 2 + (yy - size / 2) ** 2)\n",
    "    ring = torch.exp(-((r_center - size * 0.35) / (size * 0.01)) ** 2) * 0.3\n",
    "    lattice_fft = lattice_fft + torch.fft.fft2(ring)\n",
    "    # Pre-compute 50 key blur frames (only 50 FFTs, not n_frames)\n",
    "    N_KEY = 50\n",
    "    key_abs = torch.linspace(0, 1, N_KEY, device=device)\n",
    "    key_sigmas = (key_abs ** 2 * spacing * 0.5).view(N_KEY, 1, 1)\n",
    "    key_filters = torch.exp(-2 * np.pi ** 2 * key_sigmas ** 2 * freq_r2.unsqueeze(0))\n",
    "    key_frames = torch.fft.ifft2(lattice_fft.unsqueeze(0) * key_filters).real\n",
    "    # Precompute Fresnel radial grid\n",
    "    r_norm_sq = (r_center / size) ** 2\n",
    "    # Map each output frame to key frames via |defocus|\n",
    "    defocus = torch.linspace(-1, 1, n_frames, device=device)\n",
    "    abs_defocus = torch.abs(defocus)\n",
    "    idx_float = abs_defocus * (N_KEY - 1)\n",
    "    idx_low = idx_float.long().clamp(max=N_KEY - 2)\n",
    "    frac = idx_float - idx_low.float()\n",
    "    # Pre-allocate output (avoids expensive torch.cat copy)\n",
    "    result = torch.empty(n_frames, size, size)\n",
    "    batch_size = min(200, n_frames)\n",
    "    for b0 in range(0, n_frames, batch_size):\n",
    "        b1 = min(b0 + batch_size, n_frames)\n",
    "        nb = b1 - b0\n",
    "        df = defocus[b0:b1]\n",
    "        bf = frac[b0:b1].view(nb, 1, 1)\n",
    "        bi = idx_low[b0:b1]\n",
    "        # Interpolate between adjacent key frames (no per-frame FFT)\n",
    "        batch = torch.lerp(key_frames[bi], key_frames[bi + 1], bf)\n",
    "        # Fresnel concentric fringes (grow with |defocus|)\n",
    "        fringe_amp = torch.abs(df).view(nb, 1, 1) * 0.3\n",
    "        fringe_k = (1.0 + torch.abs(df) * 30.0).view(nb, 1, 1)\n",
    "        result[b0:b1] = batch + fringe_amp * torch.cos(fringe_k * r_norm_sq.unsqueeze(0) * 2 * np.pi) + 1.0\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"Generated {n_frames}\u00d7{size}\u00d7{size} focal series in {elapsed:.1f}s \"\n",
    "          f\"({result.nelement() * 4 / 1e6:.0f} MB float32)\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stress Test 1: 1000 frames \u00d7 250\u00d7250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1000\u00d7250\u00d7250 focal series in 0.4s (250 MB float32)\n"
     ]
    }
   ],
   "source": [
    "data_small = generate_focal_series(1000, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Widget created in 0.41s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945df3f9fa94458587f7f2c7b151a1ef",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "<quantem.widget.show3d.Show3D object at 0x30ef9d6a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "labels = [f\"C10={d:.0f}nm\" for d in np.linspace(-500, 500, 1000)]\n",
    "w1 = Show3D(data_small, title=\"Focal Series: 1000\u00d7250\u00d7250\", fps=30, labels=labels, pixel_size=0.2)\n",
    "print(f\"Widget created in {time.time()-t0:.2f}s\")\n",
    "w1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stress Test 2: 250 frames \u00d7 1000\u00d71000 (buffer prefetch test)\n",
    "This is the target scenario for the sliding buffer optimization.\n",
    "- 250 frames \u00d7 1000\u00d71000 \u00d7 4 bytes = 1 GB total data\n",
    "- Buffer auto-capped at 64 MB \u2192 16 frames per chunk\n",
    "- At 30 FPS: ~0.53s of buffer, prefetch at 50% (~0.27s)\n",
    "**How to test:** Press play and crank the FPS slider to 30, then 60. Playback should be smooth with no stuttering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_large = generate_focal_series(250, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "labels = [f\"C10={d:.0f}nm\" for d in np.linspace(-500, 500, 250)]\n",
    "w2 = Show3D(data_large, title=\"Buffer Test: 250\u00d71000\u00d71000\", fps=30, labels=labels, pixel_size=0.1)\n",
    "print(f\"Widget created in {time.time()-t0:.2f}s\")\n",
    "print(f\"Buffer size: {w2._buffer_size} frames ({w2._buffer_size * 1000 * 1000 * 4 / 1e6:.0f} MB)\")\n",
    "w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}